{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lJB0WR8REWr"
      },
      "outputs": [],
      "source": [
        "# # when running for the first time\n",
        "\n",
        "!pip install git+https://github.com/kwotsin/mimicry.git\n",
        "!pip3 install pyro-ppl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions import MultivariateNormal as MNormal\n",
        "from torch.distributions import Categorical\n",
        "import pyro\n",
        "from pyro.infer import MCMC, HMC as pyro_hmc, NUTS as pyro_nuts\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Optional, List, Tuple, Iterable, Callable, Union\n",
        "from tqdm import tqdm, trange\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy.special import logsumexp\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# from torch_mimicry.nets import sngan\n",
        "\n",
        "sns.set_theme('talk', style=\"white\")"
      ],
      "metadata": {
        "id": "YhV9YNRsRFKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_CHAINS = 10\n",
        "N_SAMPLES = 1000\n",
        "BURN_IN = 100\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "hHtr2CSCRFNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ema(series: Iterable, n: int) -> List:\n",
        "    \"\"\"\n",
        "    returns an n period exponential moving average for\n",
        "    the time series\n",
        "    \"\"\"\n",
        "    series = np.array(series)\n",
        "    ema = []\n",
        "    j = 1\n",
        "\n",
        "    #get n sma first and calculate the next n period ema\n",
        "    sma = sum(series[:n]) / n\n",
        "    multiplier = 2 / float(1 + n)\n",
        "    ema.append(sma)\n",
        "\n",
        "    #EMA(current) = ( (Price(current) - EMA(prev) ) x Multiplier) + EMA(prev)\n",
        "    ema.append(( (series[n] - sma) * multiplier) + sma)\n",
        "\n",
        "    #now calculate the rest of the values\n",
        "    for i in series[n+1:]:\n",
        "        tmp = ( (i - ema[j]) * multiplier) + ema[j]\n",
        "        j = j + 1\n",
        "        ema.append(tmp)\n",
        "\n",
        "    return ema"
      ],
      "metadata": {
        "id": "liPPXnTMRFPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HMC(start,\n",
        "        target,\n",
        "        n_samples: int,\n",
        "        burn_in: int,\n",
        "        *,\n",
        "        step_size: float,\n",
        "        num_leapfrog_steps: float = 1,\n",
        "        verbose: bool = False) -> torch.FloatTensor:\n",
        "    \"\"\"\n",
        "    Hamiltonian Monte Carlo\n",
        "\n",
        "    Args:\n",
        "        start - strating points of shape [n_chains x dim]\n",
        "        target - target distribution instance with method \"log_prob\"\n",
        "        n_samples - number of last samples from each chain to return\n",
        "        burn_in - number of first samples from each chain to throw away\n",
        "        step_size - step size for drift term\n",
        "        verbose - whether to show iterations' bar\n",
        "\n",
        "    Returns:\n",
        "        tensor of chains with shape [n_samples, n_chains, dim], acceptance rates for each iteration\n",
        "    \"\"\"\n",
        "\n",
        "    x = start.clone()\n",
        "    x.requires_grad_(False)\n",
        "    def energy(z):\n",
        "        z = z[\"points\"]\n",
        "        return -target.log_prob(z).sum()\n",
        "\n",
        "    kernel = pyro_hmc(\n",
        "        potential_fn=energy, step_size=step_size, num_steps=num_leapfrog_steps, full_mass=False\n",
        "        )\n",
        "\n",
        "    init_params = {\"points\": x}\n",
        "    mcmc_true = MCMC(\n",
        "        kernel=kernel,\n",
        "        num_samples=n_samples,\n",
        "        initial_params=init_params,\n",
        "        warmup_steps=burn_in,\n",
        "    )\n",
        "    mcmc_true.run()\n",
        "\n",
        "    q_true = mcmc_true.get_samples(group_by_chain=True)[\"points\"]\n",
        "    samples_true = q_true.view(-1, *start.shape).detach().cpu()\n",
        "\n",
        "    return samples_true"
      ],
      "metadata": {
        "id": "EhpcWaeqRFSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MALA(start: torch.FloatTensor,\n",
        "        target,\n",
        "        n_samples: int,\n",
        "        burn_in: int,\n",
        "        *,\n",
        "        step_size: float,\n",
        "        verbose: bool=False) -> Tuple[torch.FloatTensor, List]:\n",
        "    \"\"\"\n",
        "    Metropolis-Adjusted Langevin Algorithm with Normal proposal\n",
        "\n",
        "    Args:\n",
        "        start - strating points of shape [n_chains x dim]\n",
        "        target - target distribution instance with method \"log_prob\"\n",
        "        step_size - step size for drift term\n",
        "        verbose - whether show iterations' bar\n",
        "\n",
        "    Returns:\n",
        "        sequence of slices per each iteration, acceptance rates per each iteration\n",
        "    \"\"\"\n",
        "    std_normal = MNormal(torch.zeros(start.shape[-1], device=start.device), torch.eye(start.shape[-1], device=start.device))\n",
        "    chains = []\n",
        "    acceptance_rate = []\n",
        "\n",
        "    x = start.clone()\n",
        "    x.requires_grad_(True)\n",
        "    x.grad = None\n",
        "    logp_x = target.log_prob(x)\n",
        "    grad_x = torch.autograd.grad(logp_x.sum(), x)[0]\n",
        "\n",
        "    range_ = trange if verbose else range\n",
        "    for step_id in range_(n_samples + burn_in):\n",
        "        noise =  torch.randn_like(x)\n",
        "        y = x + step_size * grad_x + noise * (2 * step_size) ** .5\n",
        "\n",
        "        logp_y = target.log_prob(y)\n",
        "        grad_y = torch.autograd.grad(logp_y.sum(), y)[0]\n",
        "\n",
        "        log_qyx = std_normal.log_prob(noise)\n",
        "        log_qxy = std_normal.log_prob((x - y - step_size * grad_y) / (2 * step_size) ** .5)\n",
        "\n",
        "        accept_prob = torch.clamp((logp_y + log_qxy - logp_x - log_qyx).exp(), max=1)\n",
        "        mask = torch.rand_like(accept_prob) < accept_prob\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x[mask, :] = y[mask, :]\n",
        "            logp_x[mask] = logp_y[mask]\n",
        "            grad_x[mask] = grad_y[mask]\n",
        "\n",
        "        acceptance_rate.append(mask.float().mean().item())\n",
        "        if step_id >= burn_in:\n",
        "            chains.append(x.detach().data.cpu().clone())\n",
        "    chains = torch.stack(chains, 0)\n",
        "    return chains, acceptance_rate"
      ],
      "metadata": {
        "id": "GkgU9SupRFVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ISIR(start: torch.FloatTensor,\n",
        "        target,\n",
        "        proposal,\n",
        "        n_samples: int,\n",
        "        burn_in: int,\n",
        "        *,\n",
        "        n_particles: int,\n",
        "        verbose: bool=False) -> Tuple[List[torch.FloatTensor], List]:\n",
        "    \"\"\"\n",
        "    Iterated Sampling Importance Resampling\n",
        "\n",
        "    Args:\n",
        "        start - strating points of shape [n_chains x dim]\n",
        "        target - target distribution instance with method \"log_prob\"\n",
        "        proposal - proposal distribution instance with methods \"log_prob\" and \"sample\"\n",
        "        n_samples - number of last samples from each chain to return\n",
        "        burn_in - number of first samples from each chain to throw away\n",
        "        n_particles - number of particles including one from previous step\n",
        "        verbose - whether to show iterations' bar\n",
        "\n",
        "    Returns:\n",
        "        tensor of chains with shape [n_samples, n_chains, dim], acceptance rates for each iteration\n",
        "    \"\"\"\n",
        "    chains = []\n",
        "    acceptance_rate = []\n",
        "\n",
        "    x = start.clone()\n",
        "    logp_x = target.log_prob(x)\n",
        "    logq_x = proposal.log_prob(x)\n",
        "\n",
        "    range_ = trange if verbose else range\n",
        "    for step_id in range_(n_samples + burn_in):\n",
        "        particles = proposal.sample((x.shape[0], n_particles - 1))\n",
        "        logqs = torch.cat([logq_x[:, None], proposal.log_prob(particles)], 1)\n",
        "        logps = torch.cat([logp_x[:, None], target.log_prob(particles)], 1)\n",
        "        particles = torch.cat([x[:, None, :], particles], 1)\n",
        "\n",
        "        log_weights = logps - logqs.to(logps.device)\n",
        "        indices = Categorical(logits=log_weights).sample()\n",
        "\n",
        "        x = particles[np.arange(x.shape[0]), indices.to(x.device)].detach()\n",
        "        logp_x = logps[np.arange(x.shape[0]), indices].detach()\n",
        "        logq_x = logqs[np.arange(x.shape[0]), indices.to(logq_x.device)].detach()\n",
        "\n",
        "        acceptance_rate.append((indices != 0).float().mean().item())\n",
        "        if step_id >= burn_in:\n",
        "            chains.append(x.detach().data.cpu().clone())\n",
        "    chains = torch.stack(chains, 0)\n",
        "    return chains, acceptance_rate"
      ],
      "metadata": {
        "id": "_R48KLKDRFX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TargetGAN(object):\n",
        "    def __init__(\n",
        "            self,\n",
        "            gen: nn.Module,\n",
        "            dis: nn.Module,\n",
        "            device: Union[str, int, torch.device],\n",
        "            batch_size: int = 128\n",
        "            ):\n",
        "        self.gen = gen\n",
        "        self.dim = gen.latent_dim\n",
        "        self.dis = dis\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def batch_log_prob(self, z: torch.FloatTensor):\n",
        "        magic_const = 1 #try differnt ones here\n",
        "        return  self.gen.prior.log_prob(z.to(self.device)) + magic_const * self.dis(self.gen(z.to(self.device))).squeeze()\n",
        "\n",
        "    def log_prob(self, z: torch.FloatTensor, batch_size: Optional[int] = None):\n",
        "        z_flat = z.reshape(-1, self.dim)\n",
        "        batch_size = batch_size or self.batch_size\n",
        "        return torch.cat(list(map(self.batch_log_prob, z_flat.split(batch_size, 0))), 0).reshape(z.shape[:-1])\n"
      ],
      "metadata": {
        "id": "Qnfez0HSRvEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pre-trained DC-GAN model, architecure is taken from Mimicry repo."
      ],
      "metadata": {
        "id": "EOx1Mw14R5U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "! if [ ! -f \"cifar10_dcgan_G.pth\" ]; then gdown 1k_DwjkprptuCXK_gJzFF9eUCHTD9vOUH; fi\n",
        "! if [ ! -f \"cifar10_dcgan_D.pth\" ]; then gdown 1o6cXzpAPhGZxJOJseic8oGhsuilcLdLK; fi"
      ],
      "metadata": {
        "id": "NBdlA9AKRxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DC-GAN architecture here"
      ],
      "metadata": {
        "id": "bhBSdicySonX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DCGAN\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ngpu=1,\n",
        "        nc=3,\n",
        "        nz=100,\n",
        "        ngf=64,\n",
        "        mean=(0.5, 0.5, 0.5),\n",
        "        std=(0.5, 0.5, 0.5),\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.z_dim = self.latent_dim = nz\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf, nc, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.ndim == 2:\n",
        "            input = input[..., None, None]\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "class DCGANDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ngpu=1,\n",
        "        nc=3,\n",
        "        ndf=64,\n",
        "        mean=(0.5, 0.5, 0.5),\n",
        "        std=(0.5, 0.5, 0.5),\n",
        "        output_layer=\"sigmoid\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 2, 2, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "gen = DCGANGenerator().to(device)\n",
        "dis = DCGANDiscriminator().to(device)\n",
        "\n",
        "gen.load_state_dict(torch.load('cifar10_dcgan_G.pth'))\n",
        "dis.load_state_dict(torch.load('cifar10_dcgan_D.pth'))\n",
        "gen.eval()\n",
        "dis.eval();\n",
        "\n",
        "prior = MNormal(\n",
        "    torch.zeros(gen.latent_dim).to(device), torch.eye(gen.latent_dim).to(device)\n",
        "    )\n",
        "\n",
        "gen.prior = prior\n",
        "gan_target = TargetGAN(gen, dis, device=device, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "aQkjJp_ZSbfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implement Metropolis-Hastings here"
      ],
      "metadata": {
        "id": "PT_ytcuQSbhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample here"
      ],
      "metadata": {
        "id": "WcZZZTyRSbjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_D4d3siSblg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to compute the Inception score:"
      ],
      "metadata": {
        "id": "lOpwiyAnSyO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_FID_SAMPLES = 1000\n",
        "N_STEPS = 50"
      ],
      "metadata": {
        "id": "TZwqyqrvSx2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from torch_mimicry.datasets.image_loader import get_dataset_images\n",
        "from torch_mimicry.metrics.fid import fid_utils\n",
        "from torch_mimicry.metrics.inception_model import inception_utils\n",
        "from torch_mimicry.metrics.compute_fid import compute_real_dist_stats\n",
        "\n",
        "\n",
        "def _normalize_images(images):\n",
        "    \"\"\"\n",
        "    Given a tensor of images, uses the torchvision\n",
        "    normalization method to convert floating point data to integers. See reference\n",
        "    at: https://pytorch.org/docs/stable/_modules/torchvision/utils.html#save_image\n",
        "    The function uses the normalization from make_grid and save_image functions.\n",
        "    Args:\n",
        "        images (Tensor): Batch of images of shape (N, 3, H, W).\n",
        "    Returns:\n",
        "        ndarray: Batch of normalized images of shape (N, H, W, 3).\n",
        "    \"\"\"\n",
        "    # Shift the image from [-1, 1] range to [0, 1] range.\n",
        "    min_val = float(images.min())\n",
        "    max_val = float(images.max())\n",
        "    images.clamp_(min=min_val, max=max_val)\n",
        "    images.add_(-min_val).div_(max_val - min_val + 1e-5)\n",
        "\n",
        "    # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
        "    images = images.mul_(255).add_(0.5).clamp_(0, 255).permute(0, 2, 3, 1).to(\n",
        "        'cpu', torch.uint8).numpy()\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "AO4irc3cSbnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_mimicry.metrics.inception_model import inception_utils\n",
        "from torch_mimicry.metrics.inception_score import inception_score_utils as tf_inception_score\n",
        "\n",
        "\n",
        "def inception_score(images,\n",
        "                    device=None,\n",
        "                    splits=10,\n",
        "                    log_dir='./log',\n",
        "                    seed=0,\n",
        "                    print_every=20):\n",
        "    \"\"\"\n",
        "    Computes the inception score of generated images.\n",
        "    Args:\n",
        "        images (torch.Tensor): Generated images.\n",
        "        num_samples (int): The number of samples to generate.\n",
        "        batch_size (int): Batch size per feedforward step for inception model.\n",
        "        splits (int): The number of splits to use for computing IS.\n",
        "        log_dir (str): Path to store metric computation objects.\n",
        "        seed (int): Random seed for generation.\n",
        "    Returns:\n",
        "        Mean and standard deviation of the inception score computed from using\n",
        "        num_samples generated images.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Make sure the random seeds are fixed\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Build inception\n",
        "    inception_path = os.path.join(log_dir, 'metrics/inception_model')\n",
        "    inception_utils.create_inception_graph(inception_path)\n",
        "\n",
        "    is_mean, is_std = tf_inception_score.get_inception_score(images,\n",
        "                                                             splits=splits,\n",
        "                                                             device=device)\n",
        "\n",
        "    print(\"INFO: Inception Score: {:.4f} ± {:.4f} [Time Taken: {:.4f} secs]\".\n",
        "          format(is_mean, is_std,\n",
        "                 time.time() - start_time))\n",
        "\n",
        "    return is_mean, is_std"
      ],
      "metadata": {
        "id": "iGrjD4DTTaH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}